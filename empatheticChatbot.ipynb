{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3238154,"sourceType":"datasetVersion","datasetId":1962861}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"TORCH_DISABLE_TORCHDYNAMO\"] = \"1\"\nos.environ[\"TORCHINDUCTOR_DISABLE\"] = \"1\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:20:55.666509Z","iopub.execute_input":"2025-10-22T16:20:55.667858Z","iopub.status.idle":"2025-10-22T16:20:55.672235Z","shell.execute_reply.started":"2025-10-22T16:20:55.667829Z","shell.execute_reply":"2025-10-22T16:20:55.671327Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport time\nimport random\nimport math\nimport re\nimport unicodedata\nimport string\nimport collections\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm.auto import tqdm\nimport sentencepiece as spm\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils.rnn import pad_sequence","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:21:03.577928Z","iopub.execute_input":"2025-10-22T16:21:03.578277Z","iopub.status.idle":"2025-10-22T16:21:04.837209Z","shell.execute_reply.started":"2025-10-22T16:21:03.578251Z","shell.execute_reply":"2025-10-22T16:21:04.836428Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"num_heads = 2\nembed_dim = 512\nseqLen = 256\nencoder_layers = 2\ndecoder_layers = 2\ndropout = 0.3\nff_dim = embed_dim * 4\n\nPAD_ID = 0\nBOS_ID = 1\nEOS_ID = 2\nUNK_ID = 3\n\nPAD, BOS, EOS, UNK = PAD_ID, BOS_ID, EOS_ID, UNK_ID\n\nvocab_size = 32000\n\nbatch_size = 64\nlearning_rate = 3e-4\nadam_betas = (0.9, 0.98)\nteacher_forcing_ratio = 1.0\nepochs = 30","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:21:15.334385Z","iopub.execute_input":"2025-10-22T16:21:15.334847Z","iopub.status.idle":"2025-10-22T16:21:15.340702Z","shell.execute_reply.started":"2025-10-22T16:21:15.334818Z","shell.execute_reply":"2025-10-22T16:21:15.339872Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"FILE_PATH = \"/kaggle/input/empathetic-dialogues-facebook-ai/emotion-emotion_69k.csv\"\nCOLUMNS_TO_USE = [\"Situation\", \"emotion\", \"empathetic_dialogues\", \"labels\"]\n\ndef load_data(file_path: str = FILE_PATH) -> pd.DataFrame:\n    try:\n        df = pd.read_csv(file_path, usecols=COLUMNS_TO_USE)\n        print(f\"Successfully loaded {len(df)} rows from Kaggle dataset.\")\n        return df\n    except FileNotFoundError:\n        print(f\"Error: file not found at '{file_path}'.\")\n        return pd.DataFrame()\n\ndf_raw = load_data()\n\nif not df_raw.empty:\n    print(\"\\nFirst 5 rows of loaded data:\")\n    print(df_raw.head())\n    print (len(df_raw))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:21:25.165246Z","iopub.execute_input":"2025-10-22T16:21:25.165548Z","iopub.status.idle":"2025-10-22T16:21:25.705521Z","shell.execute_reply.started":"2025-10-22T16:21:25.165523Z","shell.execute_reply":"2025-10-22T16:21:25.704703Z"}},"outputs":[{"name":"stdout","text":"Successfully loaded 64636 rows from Kaggle dataset.\n\nFirst 5 rows of loaded data:\n                                           Situation      emotion  \\\n0  I remember going to the fireworks with my best...  sentimental   \n1  I remember going to the fireworks with my best...  sentimental   \n2  I remember going to the fireworks with my best...  sentimental   \n3  I remember going to the fireworks with my best...  sentimental   \n4  I remember going to the fireworks with my best...  sentimental   \n\n                                empathetic_dialogues  \\\n0  Customer :I remember going to see the firework...   \n1  Customer :This was a best friend. I miss her.\\...   \n2              Customer :We no longer talk.\\nAgent :   \n3  Customer :Was this a friend you were in love w...   \n4             Customer :Where has she gone?\\nAgent :   \n\n                                              labels  \n0  Was this a friend you were in love with, or ju...  \n1                                Where has she gone?  \n2  Oh was this something that happened because of...  \n3                This was a best friend. I miss her.  \n4                                 We no longer talk.  \n64636\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import re\nimport unicodedata\n\ndef normalize(s: str) -> str:\n    s = \"\" if s is None else str(s)\n    s = unicodedata.normalize(\"NFC\", s).lower()\n    s = (s.replace(\"“\",\"\\\"\").replace(\"”\",\"\\\"\").replace(\"‘\",\"'\").replace(\"’\",\"'\")\n         .replace(\"—\",\"-\").replace(\"–\",\"-\").replace(\"…\",\"...\"))\n    s = re.sub(r\"\\s+\", \" \", s).strip()\n    return s\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:26:17.709603Z","iopub.execute_input":"2025-10-22T16:26:17.709950Z","iopub.status.idle":"2025-10-22T16:26:17.716002Z","shell.execute_reply.started":"2025-10-22T16:26:17.709926Z","shell.execute_reply":"2025-10-22T16:26:17.715024Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import re\n\n_CUST_SEG = r\"customer\\s*:?\\s*\"\n_AGENT_SEG = r\"agent\\s*:?\\s*\"\n\ndef extract_customer(cell: str) -> str:\n    if not isinstance(cell, str):\n        return \"\"\n    s = normalize(cell)\n    last_agent = None\n    for m in re.finditer(_AGENT_SEG, s, flags=re.I):\n        last_agent = m\n    agent_cut = last_agent.start() if last_agent else len(s)\n    matches = list(re.finditer(\n        rf\"{_CUST_SEG}(.*?)(?=\\s*(?:{_AGENT_SEG}|{_CUST_SEG}|$))\",\n        s, flags=re.I | re.S\n    ))\n    if not matches:\n        return \"\"\n    candidates = [m for m in matches if m.end() <= agent_cut]\n    last = candidates[-1] if candidates else matches[-1]\n    return normalize(last.group(1))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:26:27.228311Z","iopub.execute_input":"2025-10-22T16:26:27.228979Z","iopub.status.idle":"2025-10-22T16:26:27.235231Z","shell.execute_reply.started":"2025-10-22T16:26:27.228952Z","shell.execute_reply":"2025-10-22T16:26:27.234455Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def build_XY(df: pd.DataFrame) -> pd.DataFrame:\n    emo = df[\"emotion\"].map(normalize)\n    sit = df[\"Situation\"].map(normalize)\n    y = df[\"labels\"].map(normalize)\n    cust = df[\"empathetic_dialogues\"].map(extract_customer)\n    x = \"<emo_\" + emo + \"> <sep> \" + sit + \" <sep> \" + cust + \" Agent:\"\n    pairs = pd.DataFrame({\"X\": x, \"Y\": y})\n    pairs = pairs[(pairs.X.str.len() > 0) & (pairs.Y.str.len() > 0)].reset_index(drop=True)\n    return pairs\n\npairs = build_XY(df_raw)\nprint(pairs.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:26:31.552534Z","iopub.execute_input":"2025-10-22T16:26:31.553520Z","iopub.status.idle":"2025-10-22T16:26:34.372105Z","shell.execute_reply.started":"2025-10-22T16:26:31.553479Z","shell.execute_reply":"2025-10-22T16:26:34.371170Z"}},"outputs":[{"name":"stdout","text":"                                                   X  \\\n0  <emo_sentimental> <sep> i remember going to th...   \n1  <emo_sentimental> <sep> i remember going to th...   \n2  <emo_sentimental> <sep> i remember going to th...   \n3  <emo_sentimental> <sep> i remember going to th...   \n4  <emo_sentimental> <sep> i remember going to th...   \n\n                                                   Y  \n0  was this a friend you were in love with, or ju...  \n1                                where has she gone?  \n2  oh was this something that happened because of...  \n3                this was a best friend. i miss her.  \n4                                 we no longer talk.  \n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nif not pairs.empty:\n    train_df, rest = train_test_split(pairs, test_size=0.2, random_state=42, shuffle=True)\n    val_df, test_df = train_test_split(rest, test_size=0.5, random_state=42, shuffle=True)\n    train_df = train_df.reset_index(drop=True)\n    val_df = val_df.reset_index(drop=True)\n    test_df = test_df.reset_index(drop=True)\n    train_df.to_csv(\"train.csv\", index=False)\n    val_df.to_csv(\"val.csv\", index=False)\n    test_df.to_csv(\"test.csv\", index=False)\nelse:\n    pass\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:42:21.090888Z","iopub.execute_input":"2025-10-22T16:42:21.091164Z","iopub.status.idle":"2025-10-22T16:42:21.613616Z","shell.execute_reply.started":"2025-10-22T16:42:21.091146Z","shell.execute_reply":"2025-10-22T16:42:21.612830Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import sentencepiece as spm\nimport torch\nimport re\nimport pandas as pd\n\nif 'train_df' in locals() and not train_df.empty:\n    print(\"\\nStep 3: Training Tokenizer and Encoding Data...\")\n    train_text = pd.concat([train_df[\"X\"], train_df[\"Y\"]], axis=0).tolist()\n    with open(\"spm_train_text.txt\",\"w\",encoding=\"utf-8\") as f:\n        for s in train_text:\n            f.write(s + \"\\n\")\n\n    raw_emo_tokens = sorted(set(re.findall(r\"<emo_[^>\\s]+>\", \" \".join(train_df[\"X\"].tolist()))))\n    valid_pat = re.compile(r\"^<emo_[a-z0-9_]+>$\")\n    emo_tokens_valid = [t for t in raw_emo_tokens if valid_pat.match(t)]\n    emo_tokens_invalid = sorted(set(raw_emo_tokens) - set(emo_tokens_valid))\n\n    print(f\"Found {len(raw_emo_tokens)} emotion tokens (raw).\")\n    print(f\"Using {len(emo_tokens_valid)} valid emotion tokens:\", emo_tokens_valid[:20], \"...\" if len(emo_tokens_valid) > 20 else \"\")\n    if len(emo_tokens_invalid):\n        print(f\"Ignored {len(emo_tokens_invalid)} invalid tokens:\", emo_tokens_invalid[:10], \"...\" if len(emo_tokens_invalid) > 10 else \"\")\n\n    spm.SentencePieceTrainer.Train(\n        input=\"spm_train_text.txt\",\n        model_prefix=\"spm_bpe\",\n        vocab_size=vocab_size,\n        model_type=\"bpe\",\n        character_coverage=1.0,\n        pad_id=PAD,\n        bos_id=BOS,\n        eos_id=EOS,\n        unk_id=UNK,\n        user_defined_symbols=emo_tokens_valid + [\"<sep>\"]\n    )\n    sp = spm.SentencePieceProcessor()\n    sp.load(\"spm_bpe.model\")\n    print(f\"Tokenizer trained. Vocabulary size: {sp.get_piece_size()}.\")\n\n    emo_tags = sorted(set(re.findall(r\"<emo_([a-z0-9_]+)>\", \" \".join(train_df[\"X\"].tolist()))))\n    emotions = [\"unknown\"] + emo_tags\n    emo2id = {e:i for i,e in enumerate(emotions)}\n    id2emo = {i:e for e,i in emo2id.items()}\n    print(f\"Discovered {len(emotions)} emotion classes.\")\n\n    def encode_split(df: pd.DataFrame) -> list:\n        out = []\n        xs = df[\"X\"].tolist()\n        ys = df[\"Y\"].tolist()\n        for x, y in zip(xs, ys):\n            m = re.search(r\"<emo_([a-z0-9_]+)>\", x)\n            emo = m.group(1) if m else \"unknown\"\n            ei = emo2id.get(emo, 0)\n            src_ids = sp.encode(x, out_type=int)\n            tgt_ids = [BOS] + sp.encode(y, out_type=int) + [EOS]\n            out.append({\"src_ids\": src_ids, \"tgt_ids\": tgt_ids, \"emo_id\": ei})\n        return out\n\n    train_list = encode_split(train_df)\n    val_list = encode_split(val_df)\n    test_list = encode_split(test_df)\n    total = len(train_list) + len(val_list) + len(test_list)\n    print(f\"All splits encoded. Train={len(train_list)} Val={len(val_list)} Test={len(test_list)} Total={total}\")\n    print(\"Sample X tokens:\", train_list[0][\"src_ids\"][:32] if len(train_list) else [])\n    print(\"Sample Y tokens:\", train_list[0][\"tgt_ids\"][:32] if len(train_list) else [])\n    print(\"Sample emo_id:\", train_list[0][\"emo_id\"] if len(train_list) else None)\n    from collections import Counter\n    import matplotlib.pyplot as plt\n    \n    # Combine all source and target token IDs from the training set\n    all_ids = [tid for sample in train_list for tid in sample[\"src_ids\"] + sample[\"tgt_ids\"]]\n    \n    # Count token frequency\n    token_counts = Counter(all_ids)\n    \n    # Get the most common tokens (e.g., top 30)\n    most_common = token_counts.most_common(50)\n    \n    # Convert token IDs to token strings for readability\n    tokens = [sp.id_to_piece(i) for i, _ in most_common]\n    counts = [c for _, c in most_common]\n    \n    # Plot the results\n    plt.figure(figsize=(12, 6))\n    plt.bar(tokens, counts)\n    plt.xticks(rotation=90)\n    plt.xlabel(\"Token\")\n    plt.ylabel(\"Frequency\")\n    plt.title(\"Most Frequent Tokens in Training Data\")\n    plt.tight_layout()\n    plt.show()\n\nelse:\n    print(\"Skipping Step 3: Training DataFrame is empty.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:44:32.827352Z","iopub.execute_input":"2025-10-22T16:44:32.828000Z","iopub.status.idle":"2025-10-22T16:44:46.387340Z","shell.execute_reply.started":"2025-10-22T16:44:32.827975Z","shell.execute_reply":"2025-10-22T16:44:46.386638Z"}},"outputs":[{"name":"stdout","text":"\nStep 3: Training Tokenizer and Encoding Data...\nFound 34 emotion tokens (raw).\nUsing 33 valid emotion tokens: ['<emo_afraid>', '<emo_angry>', '<emo_annoyed>', '<emo_anticipating>', '<emo_anxious>', '<emo_apprehensive>', '<emo_ashamed>', '<emo_caring>', '<emo_confident>', '<emo_content>', '<emo_devastated>', '<emo_disappointed>', '<emo_disgusted>', '<emo_embarrassed>', '<emo_excited>', '<emo_faithful>', '<emo_furious>', '<emo_grateful>', '<emo_guilty>', '<emo_hopeful>'] ...\nIgnored 1 invalid tokens: ['<emo_(>'] \nTokenizer trained. Vocabulary size: 32000.\nDiscovered 34 emotion classes.\nAll splits encoded. Train=51708 Val=6464 Test=6464 Total=64636\nSample X tokens: [31926, 29, 31926, 37, 39, 172, 52, 142, 805, 6485, 104, 66, 1527, 54, 313, 210, 31945, 671, 112, 591, 54, 538, 152, 66, 1582, 286, 846, 909, 52, 501, 148, 261]\nSample Y tokens: [1, 215, 170, 204, 523, 12738, 112, 85, 66, 456, 170, 123, 13930, 204, 199, 31945, 2]\nSample emo_id: 26\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Count frequency of the phrase \"I'm sorry to hear that\" in your training, validation, and test sets\ndef phrase_frequency(df, phrase=\"i'm sorry to hear that\"):\n    # Normalize case to handle variations like \"I'm\", \"im\", etc.\n    texts = df[\"Y\"].str.lower().tolist()\n    count = sum(phrase in t for t in texts)\n    total = len(texts)\n    freq = count / total if total > 0 else 0\n    print(f\"Phrase '{phrase}' found {count} times in {total} samples ({freq:.2%}).\")\n\nprint(\"\\nChecking phrase frequency in dataset:\")\nphrase_frequency(train_df)\nphrase_frequency(val_df)\nphrase_frequency(test_df)\n\n\ndef phrase_search(df, patterns):\n    text = \" \".join(df[\"Y\"].str.lower().tolist())\n    counts = {p: len(re.findall(p, text)) for p in patterns}\n    for p, c in counts.items():\n        print(f\"'{p}' → {c} matches\")\n\npatterns = [r\"i[' ]?m sorry\", r\"sorry to hear\", r\"apolog\", r\"that sounds tough\"]\nphrase_search(train_df, patterns)\n\n\nmask = train_df[\"Y\"].str.lower().str.contains(\"i'm sorry to hear that\")\nemo_in_sorry = train_df.loc[mask, \"X\"].str.extract(r\"(<emo_[a-z0-9_]+>)\")[0].value_counts()\nprint(\"\\nEmotion tags most associated with 'I'm sorry to hear that':\")\nprint(emo_in_sorry.head(10))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T16:48:48.783193Z","iopub.execute_input":"2025-10-22T16:48:48.783801Z","iopub.status.idle":"2025-10-22T16:48:48.927613Z","shell.execute_reply.started":"2025-10-22T16:48:48.783755Z","shell.execute_reply":"2025-10-22T16:48:48.926834Z"}},"outputs":[{"name":"stdout","text":"\nChecking phrase frequency in dataset:\nPhrase 'i'm sorry to hear that' found 202 times in 51708 samples (0.39%).\nPhrase 'i'm sorry to hear that' found 31 times in 6464 samples (0.48%).\nPhrase 'i'm sorry to hear that' found 25 times in 6464 samples (0.39%).\n'i[' ]?m sorry' → 568 matches\n'sorry to hear' → 683 matches\n'apolog' → 70 matches\n'that sounds tough' → 1 matches\n\nEmotion tags most associated with 'I'm sorry to hear that':\n0\n<emo_sad>             38\n<emo_lonely>          27\n<emo_devastated>      17\n<emo_disappointed>    15\n<emo_ashamed>         10\n<emo_anxious>         10\n<emo_furious>          9\n<emo_angry>            6\n<emo_annoyed>          6\n<emo_afraid>           6\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def detok(ids, sp, pad_id=PAD_ID, bos_id=BOS_ID, eos_id=EOS_ID):\n    if isinstance(ids, torch.Tensor):\n        ids = ids.tolist()\n    keep = []\n    for t in ids:\n        if t == pad_id or t == bos_id:\n            continue\n        if t == eos_id:\n            break\n        keep.append(t)\n    return sp.decode(keep)\n\nif 'train_list' in locals() and len(train_list) > 0:\n    n = min(2, len(train_list))\n    for i in range(n):\n        ex = train_list[i]\n        print(\"\\n--- sample\", i, \"---\")\n        print(\"X:\", detok(ex[\"src_ids\"], sp))\n        print(\"Y:\", detok(ex[\"tgt_ids\"], sp))\n        if \"emo_id\" in ex:\n            emo_name = id2emo.get(ex[\"emo_id\"], \"unknown\") if 'id2emo' in locals() else ex[\"emo_id\"]\n            print(\"emo_id:\", ex[\"emo_id\"], \"| emo:\", emo_name)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:07:17.712926Z","iopub.execute_input":"2025-10-17T20:07:17.713199Z","iopub.status.idle":"2025-10-17T20:07:17.720703Z","shell.execute_reply.started":"2025-10-17T20:07:17.713179Z","shell.execute_reply":"2025-10-17T20:07:17.719698Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\nimport torch\n\ndef check_length_and_tensorize(batch_of_examples, max_len_source, max_len_target):\n    source_tensors, target_tensors, emo_ids = [], [], []\n    for example in batch_of_examples:\n        source_ids = example[\"src_ids\"][:max_len_source]\n        target_ids = example[\"tgt_ids\"][:max_len_target]\n        if len(target_ids) < 2:\n            target_ids = target_ids + [EOS_ID]\n        source_tensors.append(torch.tensor(source_ids, dtype=torch.long))\n        target_tensors.append(torch.tensor(target_ids, dtype=torch.long))\n        emo_ids.append(example.get(\"emo_id\", 0))\n    return source_tensors, target_tensors, emo_ids\n\ndef pad_sequences_and_create_masks(source_tensors, target_tensors, pad_token_id):\n    source_padded = pad_sequence(source_tensors, batch_first=True, padding_value=pad_token_id)\n    target_padded = pad_sequence(target_tensors, batch_first=True, padding_value=pad_token_id)\n    target_input, target_output = target_padded[:, :-1], target_padded[:, 1:]\n    source_padding_mask = (source_padded == pad_token_id)\n    target_padding_mask = (target_input == pad_token_id)\n    return source_padded, source_padding_mask, target_input, target_output, target_padding_mask\n\ndef create_batch_collator(max_len_source, max_len_target, pad_token_id):\n    def collate_function(batch_of_examples):\n        source_tensors, target_tensors, emo_ids = check_length_and_tensorize(\n            batch_of_examples, max_len_source, max_len_target\n        )\n        src, src_pad, tgt_in, tgt_out, tgt_pad = pad_sequences_and_create_masks(\n            source_tensors, target_tensors, pad_token_id\n        )\n        return {\n            \"src\": src,\n            \"src_pad\": src_pad,\n            \"tgt_in\": tgt_in,\n            \"tgt_out\": tgt_out,\n            \"tgt_pad\": tgt_pad,\n            \"emo_ids\": torch.tensor(emo_ids, dtype=torch.long)\n        }\n    return collate_function\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:07:23.383590Z","iopub.execute_input":"2025-10-17T20:07:23.383976Z","iopub.status.idle":"2025-10-17T20:07:23.391535Z","shell.execute_reply.started":"2025-10-17T20:07:23.383951Z","shell.execute_reply":"2025-10-17T20:07:23.390679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ncollate_fn = create_batch_collator(\n    max_len_source=seqLen,\n    max_len_target=seqLen,\n    pad_token_id=PAD_ID\n)\n\nprint(\"Creating PyTorch DataLoaders...\")\n\ntrain_loader = DataLoader(\n    train_list,\n    batch_size=batch_size,\n    shuffle=True,\n    collate_fn=collate_fn,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_list,\n    batch_size=batch_size,\n    shuffle=False,\n    collate_fn=collate_fn\n)\n\ntest_loader = DataLoader(\n    test_list,\n    batch_size=batch_size,\n    shuffle=False,\n    collate_fn=collate_fn\n)\n\nprint(\"DataLoaders initialized.\")\nprint(f\"Train loader batches: {len(train_loader)}\")\nprint(f\"Validation loader batches: {len(val_loader)}\")\n\nif len(train_loader) > 0:\n    batch = next(iter(train_loader))\n    print(batch[\"src\"].shape)\n    print(batch[\"tgt_in\"].shape)\n    print(batch[\"tgt_out\"].shape)\n    print(batch[\"src_pad\"].shape)\n    print(batch[\"tgt_pad\"].shape)\n    print(batch[\"emo_ids\"].shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:07:28.751232Z","iopub.execute_input":"2025-10-17T20:07:28.751497Z","iopub.status.idle":"2025-10-17T20:07:28.820226Z","shell.execute_reply.started":"2025-10-17T20:07:28.751477Z","shell.execute_reply":"2025-10-17T20:07:28.819497Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\ndef make_causal_mask(size):\n    mask = torch.triu(torch.ones(size, size, dtype=torch.bool), diagonal=1)\n    return mask.unsqueeze(0).unsqueeze(0)\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model: int, max_len: int = 5000, dropout: float = 0.1):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        position = torch.arange(max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n        pe = torch.zeros(max_len, 1, d_model)\n        pe[:, 0, 0::2] = torch.sin(position * div_term)\n        pe[:, 0, 1::2] = torch.cos(position * div_term)\n        self.register_buffer('pe', pe)\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        seq_len = x.size(1)\n        x = x + self.pe[:seq_len].transpose(0, 1)\n        return self.dropout(x)\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, d_model: int, num_heads: int, dropout: float = 0.1):\n        super().__init__()\n        assert d_model % num_heads == 0\n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.d_k = d_model // num_heads\n        self.q_proj = nn.Linear(d_model, d_model)\n        self.k_proj = nn.Linear(d_model, d_model)\n        self.v_proj = nn.Linear(d_model, d_model)\n        self.out_proj = nn.Linear(d_model, d_model)\n        self.dropout = nn.Dropout(dropout)\n    def forward(self, query, key, value, mask=None):\n        N, Lq, d_model = query.shape\n        Lk = key.shape[1]\n        Q = self.q_proj(query).view(N, Lq, self.num_heads, self.d_k).transpose(1, 2)\n        K = self.k_proj(key).view(N, Lk, self.num_heads, self.d_k).transpose(1, 2)\n        V = self.v_proj(value).view(N, Lk, self.num_heads, self.d_k).transpose(1, 2)\n        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n        if mask is not None:\n            scores = scores.masked_fill(mask, float('-inf'))\n        attention_weights = self.dropout(F.softmax(scores, dim=-1))\n        context = torch.matmul(attention_weights, V)\n        context = context.transpose(1, 2).contiguous().view(N, Lq, d_model)\n        return self.out_proj(context)\n\nclass PositionwiseFeedForward(nn.Module):\n    def __init__(self, d_model: int, d_ff: int, dropout: float = 0.1):\n        super().__init__()\n        self.w_1 = nn.Linear(d_model, d_ff)\n        self.w_2 = nn.Linear(d_ff, d_model)\n        self.dropout = nn.Dropout(dropout)\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return self.w_2(self.dropout(F.gelu(self.w_1(x))))\n\nclass EncoderLayer(nn.Module):\n    def __init__(self, d_model: int, num_heads: int, d_ff: int, dropout: float = 0.1):\n        super().__init__()\n        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n        self.attn_norm = nn.LayerNorm(d_model)\n        self.ffn_norm = nn.LayerNorm(d_model)\n        self.attn_dropout = nn.Dropout(dropout)\n        self.ffn_dropout = nn.Dropout(dropout)\n    def forward(self, src: torch.Tensor, src_pad_mask: torch.BoolTensor) -> torch.Tensor:\n        attn_mask = src_pad_mask.unsqueeze(1).unsqueeze(2)\n        norm_src = self.attn_norm(src)\n        attn_out = self.self_attn(norm_src, norm_src, norm_src, mask=attn_mask)\n        src = src + self.attn_dropout(attn_out)\n        norm_src = self.ffn_norm(src)\n        ffn_out = self.ffn(norm_src)\n        src = src + self.ffn_dropout(ffn_out)\n        return src\n\nclass DecoderLayer(nn.Module):\n    def __init__(self, d_model: int, num_heads: int, d_ff: int, dropout: float = 0.1):\n        super().__init__()\n        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n        self.cross_attn = MultiHeadAttention(d_model, num_heads, dropout)\n        self.attn1_norm = nn.LayerNorm(d_model)\n        self.attn2_norm = nn.LayerNorm(d_model)\n        self.ffn_norm = nn.LayerNorm(d_model)\n        self.attn1_dropout = nn.Dropout(dropout)\n        self.attn2_dropout = nn.Dropout(dropout)\n        self.ffn_dropout = nn.Dropout(dropout)\n        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n    def forward(self, tgt: torch.Tensor, memory: torch.Tensor, tgt_pad_mask: torch.BoolTensor, memory_pad_mask: torch.BoolTensor) -> torch.Tensor:\n        L_tgt = tgt.size(1)\n        causal_mask = make_causal_mask(L_tgt).to(tgt.device)\n        tgt_attn_pad_mask = tgt_pad_mask.unsqueeze(1).unsqueeze(2)\n        full_tgt_mask = tgt_attn_pad_mask | causal_mask\n        norm_tgt = self.attn1_norm(tgt)\n        attn_out1 = self.self_attn(norm_tgt, norm_tgt, norm_tgt, mask=full_tgt_mask)\n        tgt = tgt + self.attn1_dropout(attn_out1)\n        mem_attn_mask = memory_pad_mask.unsqueeze(1).unsqueeze(2)\n        norm_tgt = self.attn2_norm(tgt)\n        attn_out2 = self.cross_attn(query=norm_tgt, key=memory, value=memory, mask=mem_attn_mask)\n        tgt = tgt + self.attn2_dropout(attn_out2)\n        norm_tgt = self.ffn_norm(tgt)\n        ffn_out = self.ffn(norm_tgt)\n        tgt = tgt + self.ffn_dropout(ffn_out)\n        return tgt\n\nclass Encoder(nn.Module):\n    def __init__(self, vocab_size: int, d_model: int, num_heads: int, d_ff: int, num_layers: int, dropout: float = 0.1, max_len: int = 5000):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=PAD_ID)\n        self.pos_encoder = PositionalEncoding(d_model, max_len, dropout)\n        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n        self.norm = nn.LayerNorm(d_model)\n    def forward(self, src: torch.Tensor, src_pad_mask: torch.BoolTensor) -> torch.Tensor:\n        src = self.embedding(src) * math.sqrt(self.embedding.embedding_dim)\n        src = self.pos_encoder(src)\n        for layer in self.layers:\n            src = layer(src, src_pad_mask)\n        return self.norm(src)\n\nclass Decoder(nn.Module):\n    def __init__(self, vocab_size: int, d_model: int, num_heads: int, d_ff: int, num_layers: int, dropout: float = 0.1, max_len: int = 5000):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=PAD_ID)\n        self.pos_decoder = PositionalEncoding(d_model, max_len, dropout)\n        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n        self.norm = nn.LayerNorm(d_model)\n    def forward(self, tgt: torch.Tensor, memory: torch.Tensor, tgt_pad_mask: torch.BoolTensor, memory_pad_mask: torch.BoolTensor) -> torch.Tensor:\n        tgt = self.embedding(tgt) * math.sqrt(self.embedding.embedding_dim)\n        tgt = self.pos_decoder(tgt)\n        for layer in self.layers:\n            tgt = layer(tgt, memory, tgt_pad_mask, memory_pad_mask)\n        return self.norm(tgt)\n\nclass Transformer(nn.Module):\n    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=embed_dim, num_heads=num_heads, d_ff=ff_dim, num_encoder_layers=encoder_layers, num_decoder_layers=decoder_layers, dropout=dropout, max_len=256, num_emotions=None):\n        super().__init__()\n        self.encoder = Encoder(src_vocab_size, d_model, num_heads, d_ff, num_encoder_layers, dropout, max_len)\n        self.decoder = Decoder(tgt_vocab_size, d_model, num_heads, d_ff, num_decoder_layers, dropout, max_len)\n        self.generator = nn.Linear(d_model, tgt_vocab_size)\n        self.emo_head = nn.Linear(d_model, num_emotions) if num_emotions is not None else None\n        for p in self.parameters():\n            if p.dim() > 1:\n                nn.init.xavier_uniform_(p)\n        self.generator.weight = self.decoder.embedding.weight\n    def forward(self, src: torch.Tensor, tgt_in: torch.Tensor, src_pad: torch.BoolTensor, tgt_pad: torch.BoolTensor):\n        memory = self.encoder(src, src_pad)\n        output = self.decoder(tgt_in, memory, tgt_pad, src_pad)\n        logits = self.generator(output)\n        emo_logits = None\n        if self.emo_head is not None:\n            mask = (~src_pad).float().unsqueeze(-1)\n            pooled = (memory * mask).sum(dim=1) / mask.sum(dim=1).clamp_min(1.0)\n            emo_logits = self.emo_head(pooled)\n        return logits, emo_logits\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:07:33.615092Z","iopub.execute_input":"2025-10-17T20:07:33.615387Z","iopub.status.idle":"2025-10-17T20:07:33.642620Z","shell.execute_reply.started":"2025-10-17T20:07:33.615365Z","shell.execute_reply":"2025-10-17T20:07:33.641836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass AdamWLite:\n    def __init__(self, params, lr=3e-4, betas=(0.9, 0.98), eps=1e-8, weight_decay=1e-4):\n        self.params = [p for p in params if p.requires_grad]\n        self.lr, (self.b1, self.b2), self.eps, self.wd = lr, betas, eps, weight_decay\n        self.state = {\n            id(p): {\n                \"step\": 0,\n                \"m\": torch.zeros_like(p, memory_format=torch.preserve_format),\n                \"v\": torch.zeros_like(p, memory_format=torch.preserve_format),\n            }\n            for p in self.params\n        }\n\n    @torch.no_grad()\n    def zero_grad(self, set_to_none: bool = False):\n        for p in self.params:\n            if p.grad is not None:\n                if set_to_none:\n                    p.grad = None\n                else:\n                    p.grad.zero_()\n\n    @torch.no_grad()\n    def step(self):\n        for p in self.params:\n            if p.grad is None:\n                continue\n            st = self.state[id(p)]\n            st[\"step\"] += 1\n            g = p.grad\n            m, v = st[\"m\"], st[\"v\"]\n            m.mul_(self.b1).add_(g, alpha=1 - self.b1)\n            v.mul_(self.b2).addcmul_(g, g, value=1 - self.b2)\n            t = st[\"step\"]\n            mhat = m / (1 - self.b1 ** t)\n            vhat = v / (1 - self.b2 ** t)\n            if self.wd != 0.0:\n                p.add_(p, alpha=-self.lr * self.wd)\n            p.addcdiv_(mhat, vhat.sqrt().add_(self.eps), value=-self.lr)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nnum_emotions = len(id2emo) if 'id2emo' in locals() else None\n\nmodel = Transformer(\n    src_vocab_size=vocab_size,\n    tgt_vocab_size=vocab_size,\n    d_model=embed_dim,\n    num_heads=num_heads,\n    d_ff=ff_dim,\n    num_encoder_layers=encoder_layers,\n    num_decoder_layers=decoder_layers,\n    dropout=dropout,\n    num_emotions=num_emotions\n).to(device)\n\nprint(\"Transformer Model Initialized.\")\nprint(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\nprint(f\"Emotion head classes: {num_emotions if num_emotions is not None else 0}\")\n\ncriterion_train = nn.CrossEntropyLoss(ignore_index=PAD_ID, label_smoothing=0.1)\ncriterion_eval = nn.CrossEntropyLoss(ignore_index=PAD_ID)\nemo_criterion = nn.CrossEntropyLoss()\nprint(\"Loss Function: CrossEntropyLoss + label_smoothing=0.1 (ignoring PAD tokens)\")\n\noptimizer = AdamWLite(\n    model.parameters(),\n    lr=learning_rate,\n    betas=adam_betas,\n    weight_decay=1e-4\n)\nprint(f\"Optimizer: AdamWLite (lr={learning_rate}, betas={adam_betas}, weight_decay=1e-4)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:07:40.566960Z","iopub.execute_input":"2025-10-17T20:07:40.567226Z","iopub.status.idle":"2025-10-17T20:07:41.595891Z","shell.execute_reply.started":"2025-10-17T20:07:40.567202Z","shell.execute_reply":"2025-10-17T20:07:41.594999Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.train()\nbatch = next(iter(train_loader))\n\nsrc = batch['src'].to(device)\nsrc_pad = batch['src_pad'].to(device)\ntgt_in = batch['tgt_in'].to(device)\ntgt_out = batch['tgt_out'].to(device)\ntgt_pad = batch['tgt_pad'].to(device)\nemo_ids = batch.get('emo_ids', None)\nif emo_ids is not None:\n    emo_ids = emo_ids.to(device)\n\noptimizer.zero_grad()\nout = model(src, tgt_in, src_pad, tgt_pad)\nif isinstance(out, tuple):\n    logits, emo_logits = out\nelse:\n    logits, emo_logits = out, None\n\nloss_tok = criterion_train(logits.view(-1, logits.size(-1)), tgt_out.contiguous().view(-1))\nif emo_logits is not None and emo_ids is not None:\n    loss_emo = emo_criterion(emo_logits, emo_ids)\n    loss = loss_tok + 0.1 * loss_emo\nelse:\n    loss = loss_tok\n\nloss.backward()\ntorch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\noptimizer.step()\n\nprint(\"Smoke test OK. Loss:\", float(loss))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:07:52.546174Z","iopub.execute_input":"2025-10-17T20:07:52.546899Z","iopub.status.idle":"2025-10-17T20:07:53.446603Z","shell.execute_reply.started":"2025-10-17T20:07:52.546869Z","shell.execute_reply":"2025-10-17T20:07:53.445828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clip_value = 1.0\ndef train_epoch(model, dataloader, optimizer, criterion_tok, criterion_emo=None, clip_value=clip_value, device=device):\n    model.train()\n    epoch_loss = 0.0\n    for batch in dataloader:\n        src = batch['src'].to(device)\n        src_pad = batch['src_pad'].to(device)\n        tgt_in = batch['tgt_in'].to(device)\n        tgt_out = batch['tgt_out'].to(device)\n        tgt_pad = batch['tgt_pad'].to(device)\n        emo_ids = batch.get('emo_ids', None)\n        if emo_ids is not None:\n            emo_ids = emo_ids.to(device)\n        optimizer.zero_grad()\n        out = model(src, tgt_in, src_pad, tgt_pad)\n        if isinstance(out, tuple):\n            logits, emo_logits = out\n        else:\n            logits, emo_logits = out, None\n        loss_tok = criterion_tok(logits.view(-1, logits.size(-1)), tgt_out.contiguous().view(-1))\n        if emo_logits is not None and emo_ids is not None and criterion_emo is not None:\n            loss_emo = criterion_emo(emo_logits, emo_ids)\n            loss = loss_tok + 0.1 * loss_emo\n        else:\n            loss = loss_tok\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n        optimizer.step()\n        epoch_loss += loss.item()\n    return epoch_loss / max(1, len(dataloader))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T17:25:20.696312Z","iopub.execute_input":"2025-10-17T17:25:20.696900Z","iopub.status.idle":"2025-10-17T17:25:20.703293Z","shell.execute_reply.started":"2025-10-17T17:25:20.696879Z","shell.execute_reply":"2025-10-17T17:25:20.702509Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_perplexity(model, dataloader, criterion_tok, criterion_emo=None, device=device):\n    model.eval()\n    total_loss = 0.0\n    with torch.no_grad():\n        for batch in dataloader:\n            src = batch['src'].to(device)\n            src_pad = batch['src_pad'].to(device)\n            tgt_in = batch['tgt_in'].to(device)\n            tgt_out = batch['tgt_out'].to(device)\n            tgt_pad = batch['tgt_pad'].to(device)\n            emo_ids = batch.get('emo_ids', None)\n            if emo_ids is not None:\n                emo_ids = emo_ids.to(device)\n            out = model(src, tgt_in, src_pad, tgt_pad)\n            if isinstance(out, tuple):\n                logits, emo_logits = out\n            else:\n                logits, emo_logits = out, None\n            loss_tok = criterion_tok(logits.view(-1, logits.size(-1)), tgt_out.contiguous().view(-1))\n            if emo_logits is not None and emo_ids is not None and criterion_emo is not None:\n                loss_emo = criterion_emo(emo_logits, emo_ids)\n                loss = loss_tok + 0.1 * loss_emo\n            else:\n                loss = loss_tok\n            total_loss += loss.item()\n    avg_loss = total_loss / max(1, len(dataloader))\n    perplexity = math.exp(avg_loss)\n    return avg_loss, perplexity\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:08:03.405269Z","iopub.execute_input":"2025-10-17T20:08:03.406267Z","iopub.status.idle":"2025-10-17T20:08:03.413771Z","shell.execute_reply.started":"2025-10-17T20:08:03.406229Z","shell.execute_reply":"2025-10-17T20:08:03.412943Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install sacrebleu rouge-score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:08:07.824484Z","iopub.execute_input":"2025-10-17T20:08:07.825204Z","iopub.status.idle":"2025-10-17T20:08:10.981369Z","shell.execute_reply.started":"2025-10-17T20:08:07.825175Z","shell.execute_reply":"2025-10-17T20:08:10.980590Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nimport math\nimport os\nfrom tqdm.auto import tqdm\n\nMODEL_SAVE_PATH = 'best_transformer_model.pt'\n\ndef _get_lr(optimizer):\n    if hasattr(optimizer, \"param_groups\"):\n        return optimizer.param_groups[0][\"lr\"]\n    return getattr(optimizer, \"lr\", None)\n\ndef _set_lr(optimizer, new_lr):\n    if hasattr(optimizer, \"param_groups\"):\n        for pg in optimizer.param_groups:\n            pg[\"lr\"] = new_lr\n    else:\n        optimizer.lr = new_lr\n\ndef _greedy_decode_texts(model, sp, batch, max_new_tokens=64):\n    src = batch['src'].to(device)\n    src_pad = batch['src_pad'].to(device)\n    B = src.size(0)\n    tgt = torch.full((B,1), BOS_ID, dtype=torch.long, device=src.device)\n    finished = torch.zeros(B, dtype=torch.bool, device=src.device)\n    for _ in range(max_new_tokens):\n        tgt_pad = (tgt == PAD_ID)\n        out = model(src, tgt, src_pad, tgt_pad)\n        logits = out[0] if isinstance(out, tuple) else out\n        next_token = logits[:,-1,:].argmax(dim=-1, keepdim=True)\n        tgt = torch.cat([tgt, next_token], dim=1)\n        finished |= (next_token.squeeze(1) == EOS_ID)\n        if bool(finished.all()):\n            break\n    preds = []\n    refs = []\n    for i in range(B):\n        preds.append(detok(tgt[i].tolist(), sp, pad_id=PAD_ID, bos_id=BOS_ID, eos_id=EOS_ID))\n        refs.append(detok(batch['tgt_out'][i].tolist(), sp, pad_id=PAD_ID, bos_id=BOS_ID, eos_id=EOS_ID))\n    return preds, refs\n\ndef _eval_text_metrics(model, val_loader, sp, max_batches=10):\n    try:\n        from sacrebleu import corpus_bleu\n        from sacrebleu.metrics import CHRF\n        from rouge_score import rouge_scorer\n    except Exception:\n        print(\"Metrics packages missing; install sacrebleu and rouge-score to compute BLEU/chrF/ROUGE-L.\")\n        return {\"bleu\": 0.0, \"chrf\": 0.0, \"rougeL\": 0.0}\n    H = []\n    R = []\n    with torch.no_grad():\n        it = iter(val_loader)\n        for _ in range(min(max_batches, len(val_loader))):\n            try:\n                batch = next(it)\n            except StopIteration:\n                break\n            preds, refs = _greedy_decode_texts(model, sp, batch, max_new_tokens=64)\n            H.extend(preds)\n            R.extend(refs)\n    if len(H) == 0:\n        return {\"bleu\": 0.0, \"chrf\": 0.0, \"rougeL\": 0.0}\n    bleu = corpus_bleu(H, [R]).score\n    chrf = CHRF(word_order=2).corpus_score(H, [R]).score\n    rs = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n    rougeL = sum(rs.score(r, h)['rougeL'].fmeasure for h, r in zip(H, R)) / len(H)\n    return {\"bleu\": float(bleu), \"chrf\": float(chrf), \"rougeL\": float(rougeL)}\n\ndef run_training_loop(\n    model, train_loader, val_loader, optimizer, criterion, epochs, device=device,\n    patience=3, lr_decay=0.5, min_lr=1e-5, sp=None, show_samples=3\n):\n    print(f\"\\nStarting training for {epochs} epochs...\")\n    best_bleu = -1.0\n    best_epoch = -1\n    bad_epochs = 0\n    train_losses = []\n    val_perplexities = []\n    for epoch in range(1, epochs + 1):\n        t0 = time.time()\n        train_loss = train_epoch(model, train_loader, optimizer, criterion, clip_value=1.0, device=device)\n        val_loss, val_ppl = evaluate_perplexity(model, val_loader, criterion_eval, device=device)\n        metrics = _eval_text_metrics(model, val_loader, sp, max_batches=10)\n        t1 = time.time()\n        cur_lr = _get_lr(optimizer)\n        print(f\"\\nEpoch {epoch:02}/{epochs} | {int((t1-t0)//60)}m {int((t1-t0)%60)}s | LR {cur_lr:.6f}\")\n        print(f\"Train Loss {train_loss:.4f} | Val Loss {val_loss:.4f} | Val PPL {val_ppl:.2f}\")\n        print(f\"Val BLEU {metrics['bleu']:.2f} | ROUGE-L {metrics['rougeL']:.4f} | chrF {metrics['chrf']:.2f}\")\n        train_losses.append(train_loss)\n        val_perplexities.append(val_ppl)\n        improved = metrics['bleu'] > best_bleu + 1e-6\n        if improved:\n            best_bleu = metrics['bleu']\n            best_epoch = epoch\n            bad_epochs = 0\n            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n            print(f\"Saved new best by BLEU: {best_bleu:.2f}\")\n        else:\n            bad_epochs += 1\n            new_lr = max(min_lr, cur_lr * lr_decay)\n            if new_lr < cur_lr:\n                _set_lr(optimizer, new_lr)\n                print(f\"LR reduced: {cur_lr:.6f} → {new_lr:.6f}\")\n            if bad_epochs >= patience:\n                print(f\"Early stopping (no BLEU improvement for {patience} epochs).\")\n                break\n        if sp is not None and show_samples > 0:\n            with torch.no_grad():\n                batch = next(iter(val_loader))\n                preds, refs = _greedy_decode_texts(model, sp, batch, max_new_tokens=64)\n                for i in range(min(show_samples, len(preds))):\n                    print(\"X:\", detok(batch['src'][i].tolist(), sp, pad_id=PAD_ID, bos_id=BOS_ID, eos_id=EOS_ID))\n                    print(\"Y_true:\", refs[i])\n                    print(\"Y_pred:\", preds[i])\n                    print(\"—\")\n    print(f\"\\nBest epoch {best_epoch} | Best BLEU {best_bleu:.2f} | Checkpoint: {MODEL_SAVE_PATH}\")\n    return train_losses, val_perplexities\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:08:21.917863Z","iopub.execute_input":"2025-10-17T20:08:21.918543Z","iopub.status.idle":"2025-10-17T20:08:21.937091Z","shell.execute_reply.started":"2025-10-17T20:08:21.918473Z","shell.execute_reply":"2025-10-17T20:08:21.936244Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = run_training_loop(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    optimizer=optimizer,\n    criterion=criterion_train,     \n    epochs=epochs,\n    device=device,\n    sp=sp\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T17:35:20.370164Z","iopub.execute_input":"2025-10-17T17:35:20.370414Z","iopub.status.idle":"2025-10-17T17:58:53.771297Z","shell.execute_reply.started":"2025-10-17T17:35:20.370395Z","shell.execute_reply":"2025-10-17T17:58:53.770486Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1) Recreate model architecture\nbest_model = Transformer(\n    src_vocab_size=vocab_size,\n    tgt_vocab_size=vocab_size,\n    d_model=embed_dim,\n    num_heads=num_heads,\n    d_ff=ff_dim,\n    num_encoder_layers=encoder_layers,\n    num_decoder_layers=decoder_layers,\n    dropout=dropout\n)\n\n# 2) Load the trained weights\nbest_model.load_state_dict(torch.load(\"best_transformer_model.pt\", map_location=\"cpu\"), strict=False)\nbest_model.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:08:31.243306Z","iopub.execute_input":"2025-10-17T20:08:31.243927Z","iopub.status.idle":"2025-10-17T20:08:32.343891Z","shell.execute_reply.started":"2025-10-17T20:08:31.243902Z","shell.execute_reply":"2025-10-17T20:08:32.343138Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch, re\nfrom collections import Counter, defaultdict\nimport copy\n\ndef _extract_emotion_tag(text: str) -> str:\n    m = re.search(r\"<emo_([^>\\s]+)>\", text)\n    return m.group(1) if m else \"none\"\n\ndef _violates_no_repeat_ngram(tokens, n):\n    if n <= 0 or len(tokens) < 2*n: return False\n    last = tuple(tokens[-n:])\n    for i in range(len(tokens)-n):\n        if tuple(tokens[i:i+n]) == last: return True\n    return False\n\n@torch.no_grad()\ndef _constrained_decode_texts_cpu(model, sp, batch, max_new_tokens=48, min_len=6, no_repeat_ngram_size=3):\n    m = copy.deepcopy(model).to(\"cpu\").eval()\n    src = batch[\"src\"].to(\"cpu\")\n    src_pad = batch[\"src_pad\"].to(\"cpu\")\n    B = src.size(0)\n    memory = m.encoder(src, src_pad)\n    tgt = torch.full((B,1), BOS_ID, dtype=torch.long)\n    finished = torch.zeros(B, dtype=torch.bool)\n    for step in range(max_new_tokens):\n        tgt_pad = (tgt == PAD_ID)\n        dec = m.decoder(tgt, memory, tgt_pad, src_pad)\n        logits = m.generator(dec)[:, -1, :]\n        if step < min_len:\n            logits[:, EOS_ID] = -1e9\n        next_ids = torch.argmax(logits, dim=-1)\n        for i in range(B):\n            if finished[i]: continue\n            tried = 0\n            while True:\n                nid = int(next_ids[i].item())\n                cand = torch.cat([tgt[i], torch.tensor([nid])], dim=0).tolist()\n                if not _violates_no_repeat_ngram(cand, no_repeat_ngram_size): break\n                logits[i, nid] = -1e9\n                nid2 = int(torch.argmax(logits[i]).item())\n                if nid2 == nid or tried > 10: break\n                next_ids[i] = nid2\n                tried += 1\n        tgt = torch.cat([tgt, next_ids.view(B,1)], dim=1)\n        finished |= (next_ids == EOS_ID)\n        if bool(finished.all()): break\n    preds = [detok(tgt[i].tolist(), sp, pad_id=PAD_ID, bos_id=BOS_ID, eos_id=EOS_ID) for i in range(B)]\n    refs  = [detok(batch[\"tgt_out\"][i].tolist(), sp, pad_id=PAD_ID, bos_id=BOS_ID, eos_id=EOS_ID) for i in range(B)]\n    return preds, refs\n\ndef analyze_vocab_usage(model, sp, loader, max_batches=20):\n    piece_counter = Counter()\n    bigram_counter = Counter()\n    emo_piece_counter = defaultdict(Counter)\n    emo_bigram_counter = defaultdict(Counter)\n    it = iter(loader)\n    n = 0\n    with torch.no_grad():\n        for _ in range(min(max_batches, len(loader))):\n            try:\n                batch = next(it)\n            except StopIteration:\n                break\n            preds, _ = _constrained_decode_texts_cpu(model, sp, batch, max_new_tokens=32, min_len=6, no_repeat_ngram_size=3)\n            for i, text in enumerate(preds):\n                pieces = sp.encode(text, out_type=int)\n                pieces_txt = [sp.id_to_piece(pid) for pid in pieces]\n                piece_counter.update(pieces_txt)\n                bigram_counter.update(zip(pieces_txt, pieces_txt[1:]))\n                x_text = detok(batch['src'][i].tolist(), sp, pad_id=PAD_ID, bos_id=BOS_ID, eos_id=EOS_ID)\n                emo = _extract_emotion_tag(x_text)\n                emo_piece_counter[emo].update(pieces_txt)\n                emo_bigram_counter[emo].update(zip(pieces_txt, pieces_txt[1:]))\n            n += 1\n    print(f\"Scanned {n} batches.\")\n    print(\"Top tokens:\", piece_counter.most_common(20))\n    print(\"Top bigrams:\", bigram_counter.most_common(20))\n    for emo in sorted(emo_piece_counter.keys())[:5]:\n        print(f\"[{emo}] Top tokens:\", emo_piece_counter[emo].most_common(10))\n    return piece_counter, bigram_counter, emo_piece_counter, emo_bigram_counter\n\nwith torch.no_grad():\n    if torch.cuda.is_available():\n        torch.cuda.synchronize()\npc, bc, epc, ebc = analyze_vocab_usage(best_model, sp, val_loader, max_batches=20)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:08:48.991100Z","iopub.execute_input":"2025-10-17T20:08:48.991333Z","iopub.status.idle":"2025-10-17T20:11:07.431943Z","shell.execute_reply.started":"2025-10-17T20:08:48.991316Z","shell.execute_reply":"2025-10-17T20:11:07.431099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch, math\nfrom sacrebleu import corpus_bleu\nfrom sacrebleu.metrics import CHRF\nfrom rouge_score import rouge_scorer\n\ndef _no_repeat_ngram(tokens, n):\n    if n <= 0 or len(tokens) < 2*n:\n        return False\n    last = tuple(tokens[-n:])\n    for i in range(len(tokens)-n):\n        if tuple(tokens[i:i+n]) == last:\n            return True\n    return False\n\n@torch.no_grad()\ndef top_p_decode_batch(model, batch, top_p=0.9, temperature=0.9, max_new_tokens=64, no_repeat_ngram_size=3, min_len=6):\n    src = batch[\"src\"].to(device)\n    src_pad = batch[\"src_pad\"].to(device)\n    B = src.size(0)\n    memory = model.encoder(src, src_pad)\n    tgt = torch.full((B,1), BOS_ID, dtype=torch.long, device=src.device)\n    finished = torch.zeros(B, dtype=torch.bool, device=src.device)\n    for step in range(max_new_tokens):\n        tgt_pad = (tgt == PAD_ID)\n        dec = model.decoder(tgt, memory, tgt_pad, src_pad)\n        logits = model.generator(dec)[:, -1, :]\n        if temperature != 1.0:\n            logits = logits / float(temperature)\n        if step < min_len:\n            logits[:, EOS_ID] = -1e9\n        sorted_logits, sorted_idx = torch.sort(logits, dim=-1, descending=True)\n        probs_sorted = torch.softmax(sorted_logits, dim=-1)\n        cumprob = torch.cumsum(probs_sorted, dim=-1)\n        keep = cumprob <= float(top_p)\n        keep[..., 0] = True\n        filtered = torch.full_like(sorted_logits, -1e9)\n        filtered[keep] = sorted_logits[keep]\n        logits = torch.full_like(logits, -1e9)\n        logits.scatter_(dim=-1, index=sorted_idx, src=filtered)\n        if finished.any():\n            logits[finished] = -1e9\n            logits[finished, EOS_ID] = 0.0\n        probs = torch.softmax(logits, dim=-1)\n        row_sums = probs.sum(dim=-1, keepdim=True)\n        zero_rows = (row_sums <= 1e-12).squeeze(1)\n        if zero_rows.any():\n            mx = torch.argmax(logits[zero_rows], dim=-1, keepdim=True)\n            nxt = torch.multinomial(probs[~zero_rows], num_samples=1) if (~zero_rows).any() else torch.empty((0,1), dtype=torch.long, device=src.device)\n            out = torch.full((B,1), EOS_ID, dtype=torch.long, device=src.device)\n            out[zero_rows] = mx\n            if (~zero_rows).any():\n                out[~zero_rows] = nxt\n            nxt = out\n        else:\n            nxt = torch.multinomial(probs, num_samples=1)\n        if no_repeat_ngram_size > 0:\n            for i in range(B):\n                if finished[i]:\n                    continue\n                cand = torch.cat([tgt[i], nxt[i]], dim=0).tolist()\n                if _no_repeat_ngram(cand, no_repeat_ngram_size):\n                    p = probs[i].clone()\n                    p[nxt[i,0]] = 0.0\n                    s = p.sum().item()\n                    if s <= 1e-12:\n                        nxt[i,0] = int(torch.argmax(logits[i]).item())\n                    else:\n                        p = p / s\n                        nxt[i,0] = int(torch.multinomial(p.view(1, -1), num_samples=1)[0,0].item())\n        tgt = torch.cat([tgt, nxt], dim=1)\n        finished |= (nxt.squeeze(1) == EOS_ID)\n        if bool(finished.all()):\n            break\n    preds = [detok(tgt[i].tolist(), sp, pad_id=PAD_ID, bos_id=BOS_ID, eos_id=EOS_ID) for i in range(B)]\n    refs = [detok(batch['tgt_out'][i].tolist(), sp, pad_id=PAD_ID, bos_id=BOS_ID, eos_id=EOS_ID) for i in range(B)]\n    return preds, refs\n\ndef eval_loader_with_decoder(loader, decoder=\"beam\", max_batches=30):\n    H, R = [], []\n    it = iter(loader)\n    for _ in range(min(max_batches, len(loader))):\n        try:\n            batch = next(it)\n        except StopIteration:\n            break\n        if decoder == \"beam\":\n            p, r = beam_decode_batch(best_model, batch)\n        else:\n            p, r = top_p_decode_batch(best_model, batch)\n        H.extend(p); R.extend(r)\n    bleu = corpus_bleu(H, [R]).score if len(H) else 0.0\n    chrf = CHRF(word_order=2).corpus_score(H, [R]).score if len(H) else 0.0\n    rs = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n    rougeL = sum(rs.score(r, h)['rougeL'].fmeasure for h, r in zip(H, R)) / max(1, len(H))\n    return {\"bleu\": float(bleu), \"chrf\": float(chrf), \"rougeL\": float(rougeL)}, H, R\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:11:17.932311Z","iopub.execute_input":"2025-10-17T20:11:17.932586Z","iopub.status.idle":"2025-10-17T20:11:17.948571Z","shell.execute_reply.started":"2025-10-17T20:11:17.932563Z","shell.execute_reply":"2025-10-17T20:11:17.947720Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_top_tokens(counter, k=20, title=\"Top predicted tokens\"):\n    top = counter.most_common(k)\n    labels = [t[0] for t in top]\n    vals = [t[1] for t in top]\n    plt.figure(figsize=(10,5))\n    plt.bar(range(len(vals)), vals)\n    plt.xticks(range(len(vals)), labels, rotation=45, ha='right')\n    plt.title(title)\n    plt.tight_layout()\n    plt.show()\n\nplot_top_tokens(pc, k=20, title=\"Top predicted tokens (validation preds)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:11:23.546059Z","iopub.execute_input":"2025-10-17T20:11:23.546321Z","iopub.status.idle":"2025-10-17T20:11:23.898395Z","shell.execute_reply.started":"2025-10-17T20:11:23.546300Z","shell.execute_reply":"2025-10-17T20:11:23.897680Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport math\n\nm = best_model if 'best_model' in globals() else model\nm.eval()\ndev = next(m.parameters()).device\n\ncriterion_eval = nn.CrossEntropyLoss(ignore_index=PAD_ID)\n\n@torch.no_grad()\ndef _eval_ppl(m, loader):\n    total, n = 0.0, 0\n    for batch in loader:\n        src = batch['src'].to(dev)\n        src_pad = batch['src_pad'].to(dev)\n        tgt_in = batch['tgt_in'].to(dev)\n        tgt_out = batch['tgt_out'].to(dev)\n        tgt_pad = batch['tgt_pad'].to(dev)\n        out = m(src, tgt_in, src_pad, tgt_pad)\n        if isinstance(out, tuple):\n            out = out[0]\n        loss = criterion_eval(out.reshape(-1, out.size(-1)),\n                              tgt_out.contiguous().view(-1))\n        total += loss.item()\n        n += 1\n    avg = total / max(1, n)\n    return avg, math.exp(avg)\n\ntest_loss, test_ppl = _eval_ppl(m, test_loader)\nprint(f\"Test Loss: {test_loss:.4f} | Test Perplexity: {test_ppl:.2f}\")\n\nbatch = next(iter(train_loader))\nwith torch.no_grad():\n    src = batch['src'].to(dev)\n    src_pad = batch['src_pad'].to(dev)\n    tgt_in = batch['tgt_in'].to(dev)\n    tgt_out = batch['tgt_out'].to(dev)\n    tgt_pad = batch['tgt_pad'].to(dev)\n    logits = m(src, tgt_in, src_pad, tgt_pad)\n    if isinstance(logits, tuple):\n        logits = logits[0]\n    loss_1batch = criterion_eval(logits.reshape(-1, logits.size(-1)),\n                                 tgt_out.contiguous().view(-1))\nprint(f\"Sanity Loss (1 train batch, eval mode): {loss_1batch.item():.4f}\")\nprint(\"Avg src len:\", int((batch['src'] != PAD_ID).sum(dim=1).float().mean().item()))\nprint(\"Avg tgt_in len:\", int((batch['tgt_in'] != PAD_ID).sum(dim=1).float().mean().item()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:18:22.388371Z","iopub.execute_input":"2025-10-17T20:18:22.388652Z","iopub.status.idle":"2025-10-17T20:21:22.699133Z","shell.execute_reply.started":"2025-10-17T20:18:22.388631Z","shell.execute_reply":"2025-10-17T20:21:22.698379Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch, random, sentencepiece as spm\n\n@torch.no_grad()\ndef greedy_decode(model, sp, src_ids, max_new_tokens=64):\n    m = model\n    m.eval()\n    dev = next(m.parameters()).device\n    src = src_ids.to(dev).unsqueeze(0)\n    src_pad = (src == PAD_ID)\n    tgt = torch.full((1,1), BOS_ID, dtype=torch.long, device=dev)\n    for _ in range(max_new_tokens):\n        tgt_pad = (tgt == PAD_ID)\n        out = m(src, tgt, src_pad, tgt_pad)\n        if isinstance(out, tuple):\n            out = out[0]\n        next_token = out[:,-1,:].argmax(dim=-1, keepdim=True)\n        tgt = torch.cat([tgt, next_token], dim=1)\n        if next_token.item() == EOS_ID:\n            break\n    return detok(tgt.squeeze(0).tolist(), sp, pad_id=PAD_ID, bos_id=BOS_ID, eos_id=EOS_ID)\n\nif 'sp' not in globals() or sp is None:\n    sp = spm.SentencePieceProcessor(); sp.load(\"spm_bpe.model\")\n\nm = best_model if 'best_model' in globals() else model\ndev = next(m.parameters()).device\n\nfor _ in range(3):\n    ex = random.choice(test_list)\n    x_text = detok(ex[\"src_ids\"], sp, pad_id=PAD_ID, bos_id=BOS_ID, eos_id=EOS_ID)\n    y_true = detok(ex[\"tgt_ids\"], sp, pad_id=PAD_ID, bos_id=BOS_ID, eos_id=EOS_ID)\n    src_ids = torch.tensor(ex[\"src_ids\"][:seqLen], dtype=torch.long, device=dev)\n    y_pred = greedy_decode(m, sp, src_ids, max_new_tokens=64)\n    print(\"\\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n    print(\"X:\", x_text)\n    print(\"Y_true:\", y_true)\n    print(\"Y_pred:\", y_pred)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:25:05.686306Z","iopub.execute_input":"2025-10-17T20:25:05.687225Z","iopub.status.idle":"2025-10-17T20:25:07.202646Z","shell.execute_reply.started":"2025-10-17T20:25:05.687185Z","shell.execute_reply":"2025-10-17T20:25:07.201851Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch, random\n\ndef _no_repeat(tokens, n):\n    if n <= 0 or tokens.numel() < 2*n: \n        return False\n    t = tokens.tolist()\n    last = t[-n:]\n    for i in range(len(t)-n):\n        if t[i:i+n] == last:\n            return True\n    return False\n\n@torch.no_grad()\ndef beam_search_decode(model, sp, src_ids, num_beams=5, max_new_tokens=64, length_penalty=0.7, no_repeat_ngram_size=3, min_len=6):\n    device_ = next(model.parameters()).device\n    model.eval()\n    src = src_ids.to(device_).unsqueeze(0)\n    src_pad = (src == PAD_ID)\n    beams = [(torch.tensor([[BOS_ID]], device=device_, dtype=torch.long), 0.0, False)]\n    for step in range(max_new_tokens):\n        new_beams = []\n        for tokens, logp, finished in beams:\n            if finished:\n                new_beams.append((tokens, logp, True))\n                continue\n            tgt_pad = (tokens == PAD_ID)\n            out = model(src, tokens, src_pad, tgt_pad)\n            if isinstance(out, tuple):\n                out = out[0]\n            logits = out[:, -1, :].squeeze(0)\n            logits[PAD_ID] = -1e9\n            if UNK_ID is not None:\n                logits[UNK_ID] = -1e9\n            if step < min_len:\n                logits[EOS_ID] = -1e9\n            probs = torch.log_softmax(logits, dim=-1)\n            topv, topi = torch.topk(probs, k=num_beams)\n            for k in range(topi.size(0)):\n                nxt = topi[k].view(1,1)\n                cand = torch.cat([tokens, nxt], dim=1)\n                if no_repeat_ngram_size > 0 and _no_repeat(cand.squeeze(0), no_repeat_ngram_size):\n                    continue\n                lp = logp + float(topv[k].item())\n                fin = nxt.item() == EOS_ID\n                new_beams.append((cand, lp, fin))\n        if not new_beams:\n            break\n        def score(entry):\n            t, lp, fin = entry\n            L = max(1, t.size(1)-1)\n            denom = ((5+L)**length_penalty)/((5+1)**length_penalty)\n            return lp/denom\n        new_beams.sort(key=score, reverse=True)\n        beams = new_beams[:num_beams]\n        if all(b[2] for b in beams):\n            break\n    best = max(beams, key=lambda x: x[1])\n    return detok(best[0].squeeze(0).tolist(), sp, pad_id=PAD_ID, bos_id=BOS_ID, eos_id=EOS_ID)\n\n@torch.no_grad()\ndef sample_decode(model, sp, src_ids, max_new_tokens=64, temperature=0.9, top_k=40, top_p=0.9, repetition_penalty=1.15, no_repeat_ngram_size=3, min_len=6):\n    import torch.nn.functional as F\n    def top_k_top_p_filtering(logits, top_k=0, top_p=0.0):\n        logits = logits.clone()\n        if top_k > 0:\n            kth = torch.topk(logits, min(top_k, logits.size(-1)))[0][..., -1, None]\n            logits[logits < kth] = -float(\"inf\")\n        if 0.0 < top_p < 1.0:\n            sorted_logits, sorted_idx = torch.sort(logits, descending=True)\n            cumprobs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n            mask = cumprobs > top_p\n            mask[..., 0] = False\n            sorted_logits[mask] = -float(\"inf\")\n            logits = torch.full_like(logits, -float(\"inf\"))\n            logits.scatter_(dim=-1, index=sorted_idx, src=sorted_logits)\n        return logits\n    device_ = next(model.parameters()).device\n    model.eval()\n    src = src_ids.to(device_).unsqueeze(0)\n    src_pad = (src == PAD_ID)\n    tgt = torch.tensor([[BOS_ID]], device=device_, dtype=torch.long)\n    for step in range(max_new_tokens):\n        tgt_pad = (tgt == PAD_ID)\n        out = model(src, tgt, src_pad, tgt_pad)\n        if isinstance(out, tuple):\n            out = out[0]\n        logits = out[:, -1, :].squeeze(0)\n        if repetition_penalty and tgt.numel() > 1:\n            uniq = torch.unique(tgt)\n            logits[uniq] = logits[uniq] / repetition_penalty\n        logits[PAD_ID] = -float(\"inf\")\n        if UNK_ID is not None:\n            logits[UNK_ID] = -float(\"inf\")\n        if step < min_len:\n            logits[EOS_ID] = -float(\"inf\")\n        if temperature != 1.0:\n            logits = logits / max(1e-6, temperature)\n        logits = top_k_top_p_filtering(logits, top_k=top_k, top_p=top_p)\n        if torch.isneginf(logits).all():\n            nxt = logits.argmax().view(1,1)\n        else:\n            probs = F.softmax(logits, dim=-1)\n            if probs.sum() <= 0:\n                nxt = logits.argmax().view(1,1)\n            else:\n                nxt = torch.multinomial(probs, 1).view(1,1)\n        new_tgt = torch.cat([tgt, nxt], dim=1)\n        if no_repeat_ngram_size > 0 and _no_repeat(new_tgt.squeeze(0), no_repeat_ngram_size):\n            mask = torch.ones_like(logits, dtype=torch.bool)\n            mask[nxt.item()] = False\n            alt = logits.masked_fill(~mask, -float(\"inf\"))\n            if not torch.isneginf(alt).all():\n                alt_probs = F.softmax(alt, dim=-1)\n                alt_nxt = torch.multinomial(alt_probs, 1).view(1,1)\n                new_tgt[:, -1] = alt_nxt.squeeze(0)\n        tgt = new_tgt\n        if tgt[0, -1].item() == EOS_ID:\n            break\n    return detok(tgt.squeeze(0).tolist(), sp, pad_id=PAD_ID, bos_id=BOS_ID, eos_id=EOS_ID)\n\nex = random.choice(test_list)\nx_text = detok(ex[\"src_ids\"], sp)\ny_true = detok(ex[\"tgt_ids\"], sp)\nsrc_ids = torch.tensor(ex[\"src_ids\"][:seqLen], dtype=torch.long, device=next(best_model.parameters()).device)\n\nprint(\"— Top-k / Top-p —\")\npred_sample = sample_decode(best_model, sp, src_ids, top_k=40, top_p=0.9, temperature=0.9)\nprint(\"X:\", x_text)\nprint(\"Y_true:\", y_true)\nprint(\"Y_pred:\", pred_sample)\n\nprint(\"\\n— Beam search —\")\npred_beam = beam_search_decode(best_model, sp, src_ids, num_beams=5, length_penalty=0.7)\nprint(\"X:\", x_text)\nprint(\"Y_true:\", y_true)\nprint(\"Y_pred:\", pred_beam)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T21:27:02.454546Z","iopub.execute_input":"2025-10-17T21:27:02.455092Z","iopub.status.idle":"2025-10-17T21:27:05.526634Z","shell.execute_reply.started":"2025-10-17T21:27:02.455064Z","shell.execute_reply":"2025-10-17T21:27:05.525836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, zipfile, torch, sentencepiece as spm\n\nART_DIR = \"export_artifacts\"\nos.makedirs(ART_DIR, exist_ok=True)\n\nCHK_PATH = \"best_transformer_model.pt\"\nTOK_MODEL = \"spm_bpe.model\"\nTOK_VOCAB = \"spm_bpe.vocab\"\n\nassert os.path.exists(CHK_PATH), \"best_transformer_model.pt not found\"\nassert os.path.exists(TOK_MODEL), \"spm_bpe.model not found\"\nassert os.path.exists(TOK_VOCAB), \"spm_bpe.vocab not found\"\n\ntorch.save(model.state_dict(), os.path.join(ART_DIR, \"transformer_state_dict.pt\"))\n\nwith open(os.path.join(ART_DIR, \"inference_config.txt\"), \"w\", encoding=\"utf-8\") as f:\n    f.write(\"\\n\".join([\n        f\"vocab_size={vocab_size}\",\n        f\"embed_dim={embed_dim}\",\n        f\"num_heads={num_heads}\",\n        f\"ff_dim={ff_dim}\",\n        f\"encoder_layers={encoder_layers}\",\n        f\"decoder_layers={decoder_layers}\",\n        f\"dropout={dropout}\",\n        f\"max_len={seqLen}\",\n        f\"PAD_ID={PAD_ID}\",\n        f\"BOS_ID={BOS_ID}\",\n        f\"EOS_ID={EOS_ID}\",\n        f\"UNK_ID={UNK_ID}\"\n    ]))\n\nfor fname in [TOK_MODEL, TOK_VOCAB]:\n    with open(fname, \"rb\") as src, open(os.path.join(ART_DIR, fname), \"wb\") as dst:\n        dst.write(src.read())\n\nZIP_PATH = \"empathetic_transformer_export.zip\"\nwith zipfile.ZipFile(ZIP_PATH, \"w\", zipfile.ZIP_DEFLATED) as z:\n    for fn in os.listdir(ART_DIR):\n        z.write(os.path.join(ART_DIR, fn), arcname=fn)\n\nprint(\"Exported:\", ZIP_PATH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T21:28:27.701753Z","iopub.execute_input":"2025-10-17T21:28:27.702386Z","iopub.status.idle":"2025-10-17T21:28:37.716185Z","shell.execute_reply.started":"2025-10-17T21:28:27.702359Z","shell.execute_reply":"2025-10-17T21:28:37.715407Z"}},"outputs":[],"execution_count":null}]}